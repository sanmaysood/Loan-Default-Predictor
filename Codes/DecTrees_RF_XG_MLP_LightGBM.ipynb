{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cT45xOo0lEJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CiRiNselHJB",
        "outputId": "52b8fd1a-ce33-41a2-b57b-ab926f4c2693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries"
      ],
      "metadata": {
        "id": "Yc853skUXnFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In3lCpz-lk6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report as cr\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "6PVBC4uuXmKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUyf2sudmTv2"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML_project/full_encoded_data_2_no_purpose.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7ygTddll-dc"
      },
      "source": [
        "\n",
        "\n",
        "# Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlVk_NeT9Yrm"
      },
      "outputs": [],
      "source": [
        "data_cleaned = data.dropna(subset = ['Label'])\n",
        "X = data_cleaned.drop(columns = ['Label'])\n",
        "y = data_cleaned['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 78)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardizing the data"
      ],
      "metadata": {
        "id": "FTpX5bKmYEX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_test_standardized = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "3zaUQQ6EX3IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "ezQy6F5MYKuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [8, 20, None],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 78), param_grid = param_grid, cv = 5)\n",
        "grid_search.fit(X_train_standardized, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Testing Accuracy: {accuracy * 100}%\")"
      ],
      "metadata": {
        "id": "0PIHUywCYJ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "0e1daa_QYXIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = DecisionTreeClassifier(max_depth = 8, random_state = 78, criterion = 'gini')\n",
        "\n",
        "best_model.fit(X_train_standardized, y_train)\n",
        "\n",
        "predictions = best_model.predict(X_test_standardized)\n",
        "\n",
        "pred_train = best_model.predict(X_train_standardized)\n",
        "acc_train = accuracy_score(y_train, pred_train)\n",
        "print(f\"Training Accuracy: {acc_train * 100}%\")\n",
        "test_acc = accuracy_score(y_test, predictions)\n",
        "print(f\"Testing Accuracy: {test_acc * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fYBGWarULVk",
        "outputId": "89dfd0af-fef6-4cd1-a639-cfc1c0e5a3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 93.67821886043907%\n",
            "Testing Accuracy: 93.71179344699004%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot of Decision Tree"
      ],
      "metadata": {
        "id": "_H3zu6_rYbxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [str(label) for label in best_model.classes_]\n",
        "\n",
        "plt.figure(figsize = (20, 16))\n",
        "tree.plot_tree(best_model, filled = True, feature_names = X.columns, class_names = class_names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_NHruy-D3P-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ],
      "metadata": {
        "id": "XotdjZ7HYgvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['0','1']\n",
        "print(cr(y_test,predictions,))"
      ],
      "metadata": {
        "id": "BwHGFIstSUDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to plot Confusion Matrix"
      ],
      "metadata": {
        "id": "iH14anYZYkkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCzzFgPePsf6"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "\n",
        "  conf_mat = confusion_matrix(y_test, y_pred)\n",
        "  tn,fp,fn,tp = conf_mat.ravel()\n",
        "\n",
        "  plt.figure(figsize = (8,6))\n",
        "  sns.heatmap([[tp,fp],[fn,tn]],annot = True,fmt = 'd', cmap = 'plasma', xticklabels = ['Positive', 'Negative'], yticklabels = ['Positive', 'Negative'])\n",
        "  plt.xlabel('True Label')\n",
        "  plt.ylabel('Predicted Label')\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.show()\n",
        "\n",
        "  precision = tp/(tp + fp)\n",
        "  recall = tp/(tp + fn)\n",
        "  f1_score = 2 * (precision * recall)/(precision + recall)\n",
        "\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall: {recall}')\n",
        "  print(f'F1 Score: {f1_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix for Decision Tree"
      ],
      "metadata": {
        "id": "SXqebar_ZLYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adUlTDlm2Bd5"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to plot ROC Curve"
      ],
      "metadata": {
        "id": "SgqNrml6ZCYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck1Ru5XoRmid"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(y_true, probabilities):\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, probabilities)\n",
        "    roc_auc = roc_auc_score(y_true, probabilities)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(fpr, tpr, color = 'orange', lw = 2, label = f'ROC curve')\n",
        "    plt.plot([0, 1], [0, 1], color = 'blue', lw = 2, linestyle = '--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f'AUC: {roc_auc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve for Decision Tree"
      ],
      "metadata": {
        "id": "fBObMmzqZSSz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKQEp_HE6od-"
      },
      "outputs": [],
      "source": [
        "probabilities = best_model.predict_proba(X_test_standardized)[:, 1]\n",
        "plot_roc_curve(y_test,probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree parameters and properties"
      ],
      "metadata": {
        "id": "6ltdIf83ZY-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_params = best_model.get_params()\n",
        "print(\"Decision Tree Parameters:\", tree_params)"
      ],
      "metadata": {
        "id": "aBCd9VI9V8SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_leaves = best_model.get_n_leaves()\n",
        "print(\"Number of Leaves:\", num_leaves)\n",
        "\n",
        "num_nodes = best_model.tree_.node_count\n",
        "print(\"Number of Nodes:\", num_nodes)\n",
        "\n",
        "max_depth = best_model.tree_.max_depth\n",
        "print(\"Maximum Depth:\", max_depth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQRb0dLoWlIb",
        "outputId": "637b8410-c28d-4008-ec3c-89bbfe2caf6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Leaves: 125\n",
            "Number of Nodes: 249\n",
            "Maximum Depth: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Features"
      ],
      "metadata": {
        "id": "cJynmq_IZkg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = best_model.feature_importances_\n",
        "feature_dict = dict(zip(X_train.columns,feature_importances))\n",
        "\n",
        "sorted_feature_importance = sorted(feature_dict.items(), key = lambda x: x[1], reverse = True)\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "c = 0\n",
        "for feature,importance in sorted_feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "    c = c+1\n",
        "    if(c == 5):\n",
        "      break"
      ],
      "metadata": {
        "id": "O2IyZC7_Wwcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZgLjI17l3cA"
      },
      "source": [
        "#RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B10ClE3zGmld"
      },
      "outputs": [],
      "source": [
        "clean_data = data.dropna(subset = ['Label'])\n",
        "X = clean_data.drop(columns = ['Label'])\n",
        "y = clean_data['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 78)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_test_standardized = scaler.transform(X_test)\n",
        "\n",
        "random_forest_classifier = RandomForestClassifier(n_estimators = 150, max_depth = 8 , min_samples_split = 2 , min_samples_leaf = 1, random_state = 78)\n",
        "\n",
        "random_forest_classifier.fit(X_train_standardized,y_train)\n",
        "\n",
        "y_pred = random_forest_classifier.predict(X_test_standardized)\n",
        "\n",
        "pred = random_forest_classifier.predict(X_train_standardized)\n",
        "train_acc = accuracy_score(y_train, pred)\n",
        "print(f\"Training Accuracy: {train_acc * 100}%\")\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f\"Testing Accuracy: {accuracy * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ],
      "metadata": {
        "id": "L422ruq9c5Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['0','1']\n",
        "print(cr(y_test, y_pred,))"
      ],
      "metadata": {
        "id": "uS4mN_SOSz6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "uhvFz3TNdGeV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcDkLOWeuIE-"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100,150,200],\n",
        "    'max_depth': [6,8,10,None]\n",
        "}\n",
        "\n",
        "\n",
        "random_forest_classifier = RandomForestClassifier(random_state = 78)\n",
        "\n",
        "grid_search = GridSearchCV(estimator = random_forest_classifier, param_grid = param_grid, cv = 5)\n",
        "\n",
        "grid_search.fit(X_train_standardized, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "predictions = best_model.predict(X_test_standardized)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Testing Accuracy: {accuracy * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix for Random Forest"
      ],
      "metadata": {
        "id": "beTOXWR9dN8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ_gA7GXnj4n"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve for Random Forest"
      ],
      "metadata": {
        "id": "rlK2rUQqdThv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4tKT8_7n2nC"
      },
      "outputs": [],
      "source": [
        "prob = random_forest_classifier.predict_proba(X_test_standardized)[:, 1]\n",
        "plot_roc_curve(y_test,prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest properties"
      ],
      "metadata": {
        "id": "pcS9rbJHda4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Trees (n_estimators):\",random_forest_classifier.n_estimators)\n",
        "print(\"max_depth:\", random_forest_classifier.max_depth)\n",
        "print(\"min_samples_split:\", random_forest_classifier.min_samples_split)\n",
        "print(\"min_samples_leaf:\", random_forest_classifier.min_samples_leaf)"
      ],
      "metadata": {
        "id": "ZDH1yNj9YrPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Features"
      ],
      "metadata": {
        "id": "ZhzRoYWEddp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = random_forest_classifier.feature_importances_\n",
        "feature_dict = dict(zip(X_train.columns,feature_importances))\n",
        "\n",
        "sorted_feature_importance = sorted(feature_dict.items(), key = lambda x: x[1], reverse = True)\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "c = 0\n",
        "for feature,importance in sorted_feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "    c = c+1\n",
        "    if(c == 5):\n",
        "      break"
      ],
      "metadata": {
        "id": "-0Hr9IV1ZsWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5-FHFlLyFcU"
      },
      "source": [
        "# XGB BOOST"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "ZLFP_EqbYb82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(random_state = 78)\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.4],\n",
        "    'max_depth': [8, 20, 32],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [0.8],\n",
        "    'n_estimators': [200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = xgb_model, param_grid = param_grid, scoring = 'accuracy', cv = 3, verbose = 1)\n",
        "\n",
        "grid_search.fit(X_train_standardized, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test_standardized)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Testing Accuracy: {acc * 100}%\")"
      ],
      "metadata": {
        "id": "o8x0r6b1wmWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaned = data.dropna(subset = ['Label'])\n",
        "X = data_cleaned.drop(columns = ['Label'])\n",
        "y = data_cleaned['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 78)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_test_standardized = scaler.transform(X_test)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    booster = 'gbtree',\n",
        "    learning_rate = 0.1,\n",
        "    max_depth = 20,\n",
        "    subsample = 0.8,\n",
        "    colsample_bytree = 0.8,\n",
        "    n_estimators = 200,\n",
        "    random_state = 78\n",
        ")\n",
        "model.fit(X_train_standardized, y_train)\n",
        "\n",
        "\n",
        "pred = model.predict(X_train_standardized)\n",
        "train_acc = accuracy_score(y_train, pred)\n",
        "print(f\"Training Accuracy: {train_acc * 100}%\")\n",
        "\n",
        "y_pred = model.predict(X_test_standardized)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Testing Accuracy: {test_acc * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIFf_M44eBcg",
        "outputId": "92fd336b-b760-45ba-d9ec-f5e6bbd88392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 99.86158075863554%\n",
            "Testing Accuracy: 93.63486376771051%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ],
      "metadata": {
        "id": "2AsnKV-DWoCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['0','1']\n",
        "print(cr(y_test,y_pred,))"
      ],
      "metadata": {
        "id": "ouRNXavqgQk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix for XGBoost"
      ],
      "metadata": {
        "id": "2LKYrfspYQSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "uGepVm6RTdjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve for XGBoost"
      ],
      "metadata": {
        "id": "4jEc_4jRYVZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob = model.predict_proba(X_test_standardized)[:, 1]\n",
        "plot_roc_curve(y_test,prob)"
      ],
      "metadata": {
        "id": "xa2YKUCVflvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Features"
      ],
      "metadata": {
        "id": "mnzZEnztYZrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = model.feature_importances_\n",
        "feature_dict = dict(zip(X_train.columns,feature_importances))\n",
        "\n",
        "sorted_feature_importance = sorted(feature_dict.items(), key = lambda x: x[1], reverse = True)\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "c = 0\n",
        "for feature,importance in sorted_feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "    c = c+1\n",
        "    if(c == 5):\n",
        "      break"
      ],
      "metadata": {
        "id": "3YCS2wyOjTvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "pGQbbojWgI78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaned = data.dropna(subset = ['Label'])\n",
        "X = data_cleaned.drop(columns = ['Label'])\n",
        "y = data_cleaned['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 78)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_standardized = scaler.fit_transform(X_train)\n",
        "X_test_standardized = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "L-ojMXjrcXAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes = (64,32,16,8,4,2),\n",
        "                      activation = 'relu',\n",
        "                      early_stopping = True,\n",
        "                      max_iter = 200,\n",
        "                      batch_size = 128,\n",
        "                      solver = 'adam',\n",
        "                      verbose = True,\n",
        "                      learning_rate_init = 1e-4,\n",
        "                      )\n",
        "\n",
        "history = mlp.fit(X_train_standardized, y_train)\n",
        "\n",
        "training_loss = history.loss_curve_\n",
        "\n",
        "plt.figure(figsize = (11, 7))\n",
        "plt.plot(training_loss, label = 'Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "train_predictions = mlp.predict(X_train_standardized)\n",
        "test_predictions = mlp.predict(X_test_standardized)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "print()\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "4F5p8qiLPLsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ],
      "metadata": {
        "id": "a0Ap4dfqG9Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['0','1']\n",
        "print(cr(y_test, test_predictions,))"
      ],
      "metadata": {
        "id": "Cpfdiin6G9Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix for MLP"
      ],
      "metadata": {
        "id": "FZxgDjShG9Lq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvGjEHOVG9Lq"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test, test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve for MLP"
      ],
      "metadata": {
        "id": "wnJsF-ceG9Lq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rob5XQ3LG9Lq"
      },
      "outputs": [],
      "source": [
        "probabilities = mlp.predict_proba(X_test_standardized)[:, 1]\n",
        "plot_roc_curve(y_test,probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "-J59G4Bt_xXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = lgb.Dataset(X_train_standardized, label = y_train)\n",
        "test_data = lgb.Dataset(X_test_standardized, label = y_test, reference = train_data)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.1,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8\n",
        "}\n",
        "\n",
        "\n",
        "num_round = 200\n",
        "bst = lgb.train(params, train_data, num_round, valid_sets = [test_data])\n",
        "\n",
        "y_train_pred = bst.predict(X_train_standardized, num_iteration = bst.best_iteration)\n",
        "y_train_pred_binary = [1 if x >= 0.5 else 0 for x in y_train_pred]\n",
        "\n",
        "y_test_pred = bst.predict(X_test_standardized, num_iteration = bst.best_iteration)\n",
        "y_test_pred_binary = [1 if x >= 0.5 else 0 for x in y_test_pred]\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred_binary)\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT3x8M4s_zUy",
        "outputId": "67d3c2d4-3d6b-4920-86bb-5db2af482b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 145183, number of negative: 588819\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.061788 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4537\n",
            "[LightGBM] [Info] Number of data points in the train set: 734002, number of used features: 93\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.197796 -> initscore=-1.400124\n",
            "[LightGBM] [Info] Start training from score -1.400124\n",
            "Training Accuracy: 0.936892542527132\n",
            "Test Accuracy: 0.9371624392430374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ],
      "metadata": {
        "id": "ADbkN5N9PUOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['0','1']\n",
        "print(cr(y_test,y_test_pred_binary,))"
      ],
      "metadata": {
        "id": "c1PJylKiPUOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix for LightGBM"
      ],
      "metadata": {
        "id": "TJUbajzBPUOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test,y_test_pred_binary)"
      ],
      "metadata": {
        "id": "viLenMcwPUOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve for LightGBM"
      ],
      "metadata": {
        "id": "HyxEseTtPUOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_raw_pred = bst.predict(X_test_standardized, num_iteration = bst.best_iteration)\n",
        "y_test_prob = 1 / (1 + np.exp(-y_test_raw_pred))\n",
        "plot_roc_curve(y_test,y_test_prob)"
      ],
      "metadata": {
        "id": "fdoJ9I-hPUOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Features"
      ],
      "metadata": {
        "id": "YihjwZC8PUOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb.plot_importance(bst, max_num_features = 5, figsize = (10, 6), importance_type = 'split')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gmY_8nsRmdvA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}